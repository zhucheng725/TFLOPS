# TFLOPS

<table>
  <tr>
      <th>   型号
      <th>    配置参数
      <th>   算例

  </tr>
  
   <tr>
      <th>   T4 
      <th>    320 Tensor Core<br>
              2560个CUDA核心 <br>
      <th>    8.1 TFLOPS (FP32)<br>
              65 TFLOPS(FP16)<br>
              130 TOPS(int8)<br>
              260 TOPS(int4)<br>

  </tr>
  
  <tr>
      <th>    AGX Xavier 
      <th>    512 Tensor Core + 64 Tensor Core+2DLA
      <th>    512Tensor Core:<br>
              1.4TFLOPS(FP32)<br>
              2.8TFLOPS(FP16)<br>
              <br>
              64Tensor Core:<br>
              22.6TOPS(INT8)<br>
              11.3FTOPS(FP16)<br>
              <br>
              2个DLA:<br>
              10TOPS(INT8)<br>
              5FTOPS(FP16)<br>

  </tr>
  
  <tr>
      <th>    TX2
      <th>    256 Tensor Core
      <th>    1.3TFLOPS(FP16)
  </tr>
  
  <tr>
      <th>    Nano
      <th>    128 Tensor Core
      <th>    0.5TFLOPS(FP16)
  </tr>
  
  <tr>
      <th>    Tesla V100
      <th>    5120 Cuda核心<br>
              640 Tensor Core
      <th>    7.8 TFLOPS(FP64)<br>
              15.7 TFLOPS(FP32)<br>
               25 TFLOPS(FP16)
  </tr>
  
  <tr>
      <th>    Drive AGX Xavier
      <th>    
      <th>    30 TOPS
  </tr>
  
  <tr>
      <th>    Drive PEGASUS
      <th>    
      <th>    320TOPS<br>
              25 TFLOPS(FP32)
  </tr>  
  
</table>
